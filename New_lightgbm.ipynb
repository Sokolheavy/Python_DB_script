{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import statsmodels\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from pandas import Timestamp\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor \n",
    "from xgboost.sklearn import XGBClassifier # sklearn’s Grid Search with parallel processing\n",
    "from xgboost import plot_importance\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('DF_File_sample.csv')\n",
    "data['SKU_Customer'] = data['DemandCustomer'] + '_' + data['SKU10']\n",
    "data_labels = data['SKU_Customer'] \n",
    "data.drop(['DemandCustomer', 'SKU10'], axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_var = [data.columns.get_loc(c) for c in data.columns if data.loc[:, c].dtypes=='object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "for i in cat_var:\n",
    "    data.iloc[:, i] = le.fit_transform(data.iloc[:, i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cat_var:\n",
    "    data.iloc[:, c] = pd.Categorical(data.iloc[:,c])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_OH = pd.get_dummies(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_OH.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### agg sales by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['year_week'] = data['Year'].astype(str) + '-' + data['Week_No'].astype(str)\n",
    "data['pre_date'] = data['year_week'].apply(lambda x: datetime.datetime.strptime(x + '-4',  \"%G-%V-%w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_null = data.groupby('pre_date').Sales.sum().loc[lambda x: x == 0].sort_values().index[0]\n",
    "data = data[data.pre_date < first_null]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-04-18 00:00:00')"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_26_week = pd.Series(sorted(data['pre_date'].unique())).iloc[-26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_34_week = pd.Series(sorted(data['pre_date'].unique())).iloc[-34]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "train = data[data['pre_date'] < first_34_week]\n",
    "test = data[data['pre_date'] >= first_26_week]\n",
    "data.drop(['pre_date', 'year_week'], axis =1, inplace = True)\n",
    "train.drop(['pre_date', 'year_week'], axis =1, inplace = True)\n",
    "test.drop(['pre_date', 'year_week'], axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "test0 = test.copy()\n",
    "test0['SKU_Customer'] = test0.merge(data_labels, left_index=True, right_index=True)['SKU_Customer']\n",
    "test['Sales'] = test0.groupby(['SKU_Customer', 'Year', 'Month_No']).Sales.transform('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.loc[:, train.columns!='Sales']\n",
    "X_test = test.loc[:, test.columns!='Sales']\n",
    "y_train = train['Sales']\n",
    "y_test = test['Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_scale(scaling_type = 'norm', X_train = X_train, X_test = X_test):\n",
    "    norm_scaler = preprocessing.StandardScaler()\n",
    "    min_max_scaler = preprocessing.MinMaxScaler() # [0, 1]\n",
    "    max_abs_scaler = preprocessing.MaxAbsScaler() # [-1, 1]\n",
    "    if scaling_type == 'norm':\n",
    "        X_train_scaled = norm_scaler.fit_transform(X_train)\n",
    "        X_test_scaled = norm_scaler.transform(X_test)\n",
    "    elif scaling_type == 'min_max':\n",
    "        X_train_scaled = min_max_scaler.fit_transform(X_train)\n",
    "        X_test_scaled = min_max_scaler.transform(X_test)\n",
    "    else: \n",
    "        X_train_scaled = max_abs_scaler.fit_transform(X_train)\n",
    "        X_test_scaled = max_abs_scaler.transform(X_test) \n",
    "    return X_train_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 650,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled, X_test_scaled = diff_scale('norm', X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scale by column(for categorical variables):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_by_col(df, scaler):\n",
    "    for var in df.select_dtypes(['number']).columns:\n",
    "        df[var] = scaler.fit_transform(df[var].values.reshape(-1,1))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_с_scaled = scale_by_col(X_train_c, norm_scaler)\n",
    "X_test_c_scaled = scale_by_col(X_test_c, norm_scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval func:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mape by every row\n",
    "def mape(y, y_pred): \n",
    "    Data = {'y': np.array(y),\n",
    "            'y_pred': np.array(y_pred)}\n",
    "    Data['MAPE'] = np.where((Data['y_pred'] == 0)&(Data['y'] == 0), 0, \\\n",
    "                           np.where((Data['y_pred'] != 0)&(Data['y']==0),1, np.abs(Data['y_pred']-Data['y'])*100/Data['y']))\n",
    "    \n",
    "    return Data['MAPE'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs(y_true - y_pred)) * 100 / np.mean(np.abs(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape_by_month(y_true, y_pred): \n",
    "    test2 = test.copy()\n",
    "    test2['Sales_pred'] = y_pred\n",
    "    test2['SKU_Customer'] = test2.merge(data_labels, left_index=True, right_index=True)['SKU_Customer']\n",
    "    test2['Sales_pred'] = test2.groupby(['Year', 'Month_No', 'SKU_Customer']).Sales_pred.transform('mean')\n",
    "    return mape(test['Sales'], test2['Sales_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y, y_pred):\n",
    "    return np.sqrt(np.mean(np.square(y - y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_by_month(y_true, y_pred): \n",
    "    test2 = test.copy()\n",
    "    test2['Sales_pred'] = y_pred\n",
    "    test2['SKU_Customer'] = test2.merge(data_labels, left_index=True, right_index=True)['SKU_Customer']\n",
    "    test2['Sales_pred'] = test2.groupby(['SKU_Customer', 'Year', 'Month_No']).Sales_pred.transform('mean')\n",
    "    return rmse(test['Sales'], test2['Sales_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAD_by_month(y, y_pred):\n",
    "    Data = {'y': np.array(y),\n",
    "            'y_pred': np.array(y_pred)}\n",
    "    \n",
    "    test2 = test.copy()\n",
    "    test2['y_pred'] = Data['y_pred']\n",
    "    test2['SKU_Customer'] = test2.merge(data_labels, left_index=True, right_index=True)['SKU_Customer']\n",
    "    test2['y_pred'] = test2.groupby(['Year', 'Month_No', 'SKU_Customer']).y_pred.transform('mean')\n",
    "    Data['y_pred'] = test2['y_pred']\n",
    "    \n",
    "    Data['MAD'] = np.where((Data['y_pred'] == 0)&(Data['y'] == 0), 0, \\\n",
    "                           np.where((Data['y_pred'] == 0)&(Data['y']!=0),1, np.abs(Data['y_pred']-Data['y'])/Data['y_pred']))\n",
    "    return Data['MAD'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ridge mape: 78.26210458316488 {'alpha': 0.99, 'fit_intercept': True}\n",
      "ridge rmse: 4449.260697701879\n",
      "ridge MAD: 2.779961216820889\n"
     ]
    }
   ],
   "source": [
    "alphas = np.arange(0, 1, 0.01)\n",
    "fit_interceptOptions = ([True, False])\n",
    "\n",
    "model = Ridge() \n",
    "scorer = make_scorer(mape, greater_is_better=False)\n",
    "\n",
    "ridge_cv = GridSearchCV(model, param_grid=dict(alpha=alphas, fit_intercept=fit_interceptOptions), scoring = scorer, n_jobs=-2)\n",
    "ridge_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"ridge mape:\", mape_by_month(y_test, ridge_cv.predict(X_test_scaled)), ridge_cv.best_params_)\n",
    "print(\"ridge rmse:\", rmse_by_month(y_test, ridge_cv.predict(X_test_scaled)))\n",
    "print(\"ridge MAD:\", MAD_by_month(y_test, ridge_cv.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lasso mape: 43.844628487904465 {'alpha': 0.29, 'fit_intercept': True}\n",
      "lasso rmse: 582.8834310653247\n",
      "ridge rmse: 0.6283063149358187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19725414.66720009, tolerance: 1416151.2387218715\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "alphas = np.arange(0, 1, 0.01)\n",
    "fit_interceptOptions = ([True, False])\n",
    "\n",
    "model = Lasso() \n",
    "scorer = make_scorer(mape, greater_is_better=False)\n",
    "\n",
    "lasso_cv = GridSearchCV(model, param_grid=dict(alpha=alphas, fit_intercept=fit_interceptOptions), scoring = scorer, n_jobs=-2)\n",
    "lasso_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"lasso mape:\", mape_by_month(y_test, lasso_cv.predict(X_test_scaled)), lasso_cv.best_params_)\n",
    "print(\"lasso rmse:\", rmse_by_month(y_test, lasso_cv.predict(X_test_scaled)))\n",
    "print(\"lasso MAD:\", MAD_by_month(y_test, lasso_cv.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ElasticNet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet mape: 43.89520986906346 {'alpha': 0.01, 'fit_intercept': True, 'l1_ratio': 0.8}\n",
      "ElasticNet rmse: 583.4014421480716\n",
      "ElasticNet MAD: 0.6331462398547043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14776034.158023834, tolerance: 1416151.2387218715\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "alphas = np.logspace(-5,2,8)\n",
    "l1_ratio = [.1, .15, .2, .25, .3,.4,.5,.6,.8]\n",
    "fit_interceptOptions = ([True, False])\n",
    "\n",
    "model = ElasticNet() \n",
    "scorer = make_scorer(mape, greater_is_better=False)\n",
    "\n",
    "ElasticNet_cv = GridSearchCV(model, param_grid=dict(alpha=alphas, l1_ratio = l1_ratio, fit_intercept=fit_interceptOptions), scoring = scorer, n_jobs=-2)\n",
    "ElasticNet_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"ElasticNet mape:\", mape_by_month(y_test, ElasticNet_cv.predict(X_test_scaled)), ElasticNet_cv.best_params_)\n",
    "print(\"ElasticNet rmse:\", rmse_by_month(y_test, ElasticNet_cv.predict(X_test_scaled)))\n",
    "print(\"ElasticNet MAD:\", MAD_by_month(y_test, ElasticNet_cv.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet mape: 43.88760884080415 {'alpha': 0.009, 'fit_intercept': True, 'l1_ratio': 0.8}\n",
      "ElasticNet rmse: 583.3577674291163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:475: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 596096359.1907067, tolerance: 1416151.2387218715\n",
      "  positive)\n"
     ]
    }
   ],
   "source": [
    "alphas = [.009, .01, .015, .02,.05,.1]\n",
    "l1_ratio = [.1,.2,.3,.4,.5,.55, .6, .65,.7,.8]\n",
    "fit_interceptOptions = ([True, False])\n",
    "\n",
    "model = ElasticNet() \n",
    "scorer = make_scorer(mape, greater_is_better=False)\n",
    "\n",
    "ElasticNet_cv = GridSearchCV(model, param_grid=dict(alpha=alphas, l1_ratio = l1_ratio, fit_intercept=fit_interceptOptions), scoring = scorer, n_jobs=-2)\n",
    "ElasticNet_cv.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"ElasticNet mape:\", mape_by_month(y_test, ElasticNet_cv.predict(X_test_scaled)), ElasticNet_cv.best_params_)\n",
    "print(\"ElasticNet rmse:\", rmse_by_month(y_test, ElasticNet_cv.predict(X_test_scaled)))\n",
    "print(\"ElasticNet MAD:\", MAD_by_month(y_test, ElasticNet_cv.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso takes the best result => tune diff scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tune diff scaling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### min_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso mape: 50.17694271242768 {'alpha': 10.0, 'fit_intercept': False, 'l1_ratio': 0.8}\n",
      "ElasticNet rmse: 351.0281888887466\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled = diff_scale('min_max', X_train, X_test)\n",
    "alphas = np.logspace(-5,2,8)\n",
    "l1_ratio = [.1, .15, .2, .25, .3,.4,.5,.6,.8]\n",
    "\n",
    "model = ElasticNet()  \n",
    "scorer = make_scorer(mape, greater_is_better=False)\n",
    "\n",
    "ElasticNet_cv_mm = GridSearchCV(model, param_grid=dict(alpha=alphas, l1_ratio=l1_ratio,fit_intercept=fit_interceptOptions), scoring = scorer, n_jobs=-2)\n",
    "ElasticNet_cv_mm.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Lasso mape:\", mape_by_month(y_test, ElasticNet_cv_mm.predict(X_test_scaled)), ElasticNet_cv_mm.best_params_)\n",
    "print(\"ElasticNet rmse:\", rmse_by_month(y_test, ElasticNet_cv_mm.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### max_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso mape: 62.50765658487119 {'alpha': 10.0, 'fit_intercept': False, 'l1_ratio': 0.8}\n",
      "ElasticNet rmse: 426.73585900075085\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled = diff_scale('max_abs', X_train, X_test)\n",
    "alphas = np.logspace(-5,2,8)\n",
    "l1_ratio = [.1, .15, .2, .25, .3,.4,.5,.6,.8]\n",
    "\n",
    "model = ElasticNet()  \n",
    "scorer = make_scorer(mape, greater_is_better=False)\n",
    "\n",
    "ElasticNet_cv_ma = GridSearchCV(model, param_grid=dict(alpha=alphas, l1_ratio=l1_ratio,fit_intercept=fit_interceptOptions), scoring = scorer, n_jobs=-2)\n",
    "ElasticNet_cv_ma.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Lasso mape:\", mape_by_month(y_test, ElasticNet_cv_ma.predict(X_test_scaled)), ElasticNet_cv_mm.best_params_)\n",
    "print(\"ElasticNet rmse:\", rmse_by_month(y_test, ElasticNet_cv_ma.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR mape: 82.48684969248089 {'C': 1.5, 'epsilon': 0.3, 'gamma': 1e-07, 'kernel': 'linear'}\n",
      "SVR rmse: 4638.55357824556\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled = diff_scale('norm', X_train, X_test)\n",
    "parameters = {'kernel': ('linear', 'rbf','poly'),\n",
    "              'C':[1.5, 10],\n",
    "              'gamma': [1e-7, 1e-4],\n",
    "              'epsilon':[0.1,0.2,0.5,0.3]}\n",
    "\n",
    "model = SVR()\n",
    "scorer = make_scorer(mape, greater_is_better=False)\n",
    "svr = GridSearchCV(model, parameters, scoring = scorer, n_jobs=-2)\n",
    "svr.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"SVR mape:\", mape_by_month(y_test, svr.predict(X_test_scaled)), svr.best_params_)\n",
    "print(\"SVR rmse:\", rmse_by_month(y_test, svr.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR mape: 82.32578475959185 {'C': 2, 'epsilon': 0.45, 'gamma': 1e-10, 'kernel': 'linear'}\n",
      "SVR rmse: 4630.3285453342405\n",
      "SVR MAD: 2.81015437625592\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled = diff_scale('norm', X_train, X_test)\n",
    "parameters = {'kernel': ['linear'],\n",
    "              'C':[1, 2, 4, 5],\n",
    "              'gamma': [1e-10, 1e-9, 1e-8, 1e-7],\n",
    "              'epsilon':[.3, .35, .45, .5]}\n",
    " \n",
    "model = SVR()\n",
    "scorer = make_scorer(mape, greater_is_better=False)\n",
    "svr = GridSearchCV(model, parameters, scoring = scorer, n_jobs=-2)\n",
    "svr.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"SVR mape:\", mape_by_month(y_test, svr.predict(X_test_scaled)), svr.best_params_)\n",
    "print(\"SVR rmse:\", rmse_by_month(y_test, svr.predict(X_test_scaled)))\n",
    "print(\"SVR MAD:\", MAD_by_month(y_test, ElasticNet_cv.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lightgbm with k-Fold:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm mape: 82.13935749134242 {'learning_rate': 0.02, 'max_depth': 7, 'n_estimators': 160, 'num_leaves': 9}\n",
      "lightgbm rmse: 4510.713280213905\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled = diff_scale('norm', X_train, X_test)\n",
    "param_grid = {\n",
    "    'n_estimators' : list(range(100, 180,10)),\n",
    "    'num_leaves': list(range(7,10, 1)),\n",
    "    # 'min_data_in_leaf': [10, 20, 40, 60, 100],\n",
    "    'max_depth': [2, 4, 6, 7, 8],\n",
    "    'learning_rate': [0.01, .016, .02, .1]}\n",
    "    # 'bagging_freq': [3, 4, 5, 6, 7],\n",
    "    # 'bagging_fraction': np.linspace(0.6, 0.95, 10),\n",
    "    # 'reg_alpha': np.linspace(0.1, 0.95, 10),\n",
    "    # 'reg_lambda': np.linspace(0.1, 0.95, 10)\n",
    "                                                  \n",
    "scorer = make_scorer(mape, greater_is_better = False)   \n",
    "gbm = GridSearchCV(lgb.LGBMRegressor(cat_features= cat_var), \n",
    "                   param_grid, \n",
    "                   scoring = scorer, n_jobs = -2)\n",
    "\n",
    "\n",
    "gbm.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"lightgbm mape:\", mape_by_month(y_test, gbm.predict(X_test_scaled)), gbm.best_params_)\n",
    "print(\"lightgbm rmse:\", rmse(y_test, gbm.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm mape: 78.86952945136558 {'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 170, 'num_leaves': 8}\n",
      "lightgbm rmse: 4422.83835990909\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled = diff_scale('norm', X_train, X_test)\n",
    "param_grid = {\n",
    "    'n_estimators' : list(range(100, 180,10)),\n",
    "    'num_leaves': list(range(7,10, 1)),\n",
    "    # 'min_data_in_leaf': [10, 20, 40, 60, 100],\n",
    "    'max_depth': [2, 4, 6, 7, 8],\n",
    "    'learning_rate': [0.01, .016, .02, .1]}\n",
    "    # 'bagging_freq': [3, 4, 5, 6, 7],\n",
    "    # 'bagging_fraction': np.linspace(0.6, 0.95, 10),\n",
    "    # 'reg_alpha': np.linspace(0.1, 0.95, 10),\n",
    "    # 'reg_lambda': np.linspace(0.1, 0.95, 10)\n",
    "                                                  \n",
    "scorer = make_scorer(mape, greater_is_better = False)   \n",
    "gbm = GridSearchCV(lgb.LGBMRegressor(cat_features= cat_var), \n",
    "                   param_grid, \n",
    "                   scoring = scorer, \n",
    "                   cv = 7,\n",
    "                   n_jobs = -2)\n",
    "\n",
    "\n",
    "gbm.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"lightgbm mape:\", mape_by_month(y_test, gbm.predict(X_test_scaled)), gbm.best_params_)\n",
    "print(\"lightgbm rmse:\", rmse(y_test, gbm.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm mape: 78.81297203627314 {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 170, 'num_leaves': 8}\n",
      "lightgbm rmse: 4422.940683731223\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled = diff_scale('norm', X_train, X_test)\n",
    "param_grid = {\n",
    "    'n_estimators' : list(range(100, 180,10)),\n",
    "    'num_leaves': list(range(7,10, 1)),\n",
    "    # 'min_data_in_leaf': [10, 20, 40, 60, 100],\n",
    "    'max_depth': [2, 4, 6, 7, 8],\n",
    "    'learning_rate': [0.01, .016, .02, .1]}\n",
    "    # 'bagging_freq': [3, 4, 5, 6, 7],\n",
    "    # 'bagging_fraction': np.linspace(0.6, 0.95, 10),\n",
    "    # 'reg_alpha': np.linspace(0.1, 0.95, 10),\n",
    "    # 'reg_lambda': np.linspace(0.1, 0.95, 10)\n",
    "                                                  \n",
    "scorer = make_scorer(mape, greater_is_better = False)   \n",
    "gbm = GridSearchCV(lgb.LGBMRegressor(cat_features= cat_var), \n",
    "                   param_grid, \n",
    "                   scoring = scorer, \n",
    "                   cv = 10,\n",
    "                   n_jobs = -2)\n",
    "\n",
    "\n",
    "gbm.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"lightgbm mape:\", mape_by_month(y_test, gbm.predict(X_test_scaled)), gbm.best_params_)\n",
    "print(\"lightgbm rmse:\", rmse(y_test, gbm.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lightgbm with Group k-Fold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = X_train['Year'].astype(str) + '_' + X_train['Week_No'].astype(str) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = X_train[['Year', 'Week_No']].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm mape: 77.56147635770547 {'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 170, 'num_leaves': 9}\n",
      "lightgbm rmse: 4368.990213180459\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled = diff_scale('norm', X_train, X_test)\n",
    "param_grid = {\n",
    "    'n_estimators' : list(range(100, 180,10)),\n",
    "    'num_leaves': list(range(7,10, 1)),\n",
    "    # 'min_data_in_leaf': [10, 20, 40, 60, 100],\n",
    "    'max_depth': [2, 4, 6, 7, 8],\n",
    "    'learning_rate': [0.01, .016, .02, .1, .2, .3]}\n",
    "    # 'bagging_freq': [3, 4, 5, 6, 7],\n",
    "    # 'bagging_fraction': np.linspace(0.6, 0.95, 10),\n",
    "    # 'reg_alpha': np.linspace(0.1, 0.95, 10),\n",
    "    # 'reg_lambda': np.linspace(0.1, 0.95, 10)\n",
    "\n",
    "    \n",
    "scorer = make_scorer(mape, greater_is_better = False)   \n",
    "gbm_g1 = GridSearchCV(lgb.LGBMRegressor(cat_features= cat_var), \n",
    "                   param_grid, \n",
    "                   scoring = scorer, \n",
    "                   n_jobs = -2,\n",
    "                   cv = GroupKFold(n_splits=5))\n",
    "\n",
    "\n",
    "gbm_g1.fit(X_train_scaled, y_train, groups=groups)\n",
    "\n",
    "print(\"lightgbm mape:\", mape_by_month(y_test, gbm_1.predict(X_test_scaled)), gbm_g1.best_params_)\n",
    "print(\"lightgbm rmse:\", rmse(y_test, gbm_g1.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB mape: 77.56147635770547\n",
      "XGB rmse: 4368.990213180459\n"
     ]
    }
   ],
   "source": [
    "# use parametesr into models:\n",
    "gbm_g1_result = lgb.LGBMRegressor(cat_features= cat_var, max_depth=7, n_estimators=170, learning_rate=0.2, num_leaves=9).fit(X_train_scaled, y_train)\n",
    "print(\"XGB mape:\", mape_by_month(y_test, gbm_g1_result.predict(X_test_scaled)))\n",
    "print(\"XGB rmse:\", rmse(y_test, gbm_g1_result.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm mape: 78.59512841291054 {'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 170, 'num_leaves': 9}\n",
      "lightgbm rmse: 4413.7326235717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled = diff_scale('norm', X_train, X_test)\n",
    "param_grid = {\n",
    "    'n_estimators' : list(range(100, 180,10)),\n",
    "    'num_leaves': list(range(7,10, 1)),\n",
    "    # 'min_data_in_leaf': [10, 20, 40, 60, 100],\n",
    "    'max_depth': [2, 4, 6, 7, 8],\n",
    "    'learning_rate': [0.01, .016, .02, .1, .2, .3]}\n",
    "    # 'bagging_freq': [3, 4, 5, 6, 7],\n",
    "    # 'bagging_fraction': np.linspace(0.6, 0.95, 10),\n",
    "    # 'reg_alpha': np.linspace(0.1, 0.95, 10),\n",
    "    # 'reg_lambda': np.linspace(0.1, 0.95, 10)\n",
    "\n",
    "    \n",
    "scorer = make_scorer(mape, greater_is_better = False)   \n",
    "gbm = GridSearchCV(lgb.LGBMRegressor(cat_features= cat_var), \n",
    "                   param_grid, \n",
    "                   scoring = scorer, \n",
    "                   n_jobs = -2,\n",
    "                   cv = GroupKFold(n_splits=6))\n",
    "\n",
    "\n",
    "gbm.fit(X_train_scaled, y_train, groups=groups)\n",
    "\n",
    "print(\"lightgbm mape:\", mape_by_month(y_test, gbm.predict(X_test_scaled)), gbm.best_params_)\n",
    "print(\"lightgbm rmse:\", rmse(y_test, gbm.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm mape: 77.96815178417387 {'learning_rate': 0.2, 'max_depth': 6, 'n_estimators': 170, 'num_leaves': 8}\n",
      "lightgbm rmse: 4386.864356700242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled = diff_scale('norm', X_train, X_test)\n",
    "param_grid = {\n",
    "    'n_estimators' : list(range(100, 180,10)),\n",
    "    'num_leaves': list(range(7,10, 1)),\n",
    "    # 'min_data_in_leaf': [10, 20, 40, 60, 100],\n",
    "    'max_depth': [2, 4, 6, 7, 8],\n",
    "    'learning_rate': [0.01, .016, .02, .1, .2, .3]}\n",
    "    # 'bagging_freq': [3, 4, 5, 6, 7],\n",
    "    # 'bagging_fraction': np.linspace(0.6, 0.95, 10),\n",
    "    # 'reg_alpha': np.linspace(0.1, 0.95, 10),\n",
    "    # 'reg_lambda': np.linspace(0.1, 0.95, 10)\n",
    "\n",
    "    \n",
    "scorer = make_scorer(mape, greater_is_better = False)   \n",
    "gbm = GridSearchCV(lgb.LGBMRegressor(cat_features= cat_var), \n",
    "                   param_grid, \n",
    "                   scoring = scorer, \n",
    "                   n_jobs = -2,\n",
    "                   cv = GroupKFold(n_splits=8))\n",
    "\n",
    "\n",
    "gbm.fit(X_train_scaled, y_train, groups=groups)\n",
    "\n",
    "print(\"lightgbm mape:\", mape_by_month(y_test, gbm.predict(X_test_scaled)), gbm.best_params_)\n",
    "print(\"lightgbm rmse:\", rmse(y_test, gbm.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm mape: 77.81430366609294 {'learning_rate': 0.2, 'max_depth': 6, 'n_estimators': 170, 'num_leaves': 9}\n",
      "lightgbm rmse: 4363.915162900023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:813: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled = diff_scale('norm', X_train, X_test)\n",
    "param_grid = {\n",
    "    'n_estimators' : list(range(100, 180,10)),\n",
    "    'num_leaves': list(range(7,10, 1)),\n",
    "    # 'min_data_in_leaf': [10, 20, 40, 60, 100],\n",
    "    'max_depth': [2, 4, 6, 7, 8],\n",
    "    'learning_rate': [0.01, .016, .02, .1, .2, .3]}\n",
    "    # 'bagging_freq': [3, 4, 5, 6, 7],\n",
    "    # 'bagging_fraction': np.linspace(0.6, 0.95, 10),\n",
    "    # 'reg_alpha': np.linspace(0.1, 0.95, 10),\n",
    "    # 'reg_lambda': np.linspace(0.1, 0.95, 10)\n",
    "\n",
    "    \n",
    "scorer = make_scorer(mape, greater_is_better = False)   \n",
    "gbm = GridSearchCV(lgb.LGBMRegressor(cat_features= cat_var), \n",
    "                   param_grid, \n",
    "                   scoring = scorer, \n",
    "                   n_jobs = -2,\n",
    "                   cv = GroupKFold(n_splits=12))\n",
    "\n",
    "\n",
    "gbm.fit(X_train_scaled, y_train, groups=groups)\n",
    "\n",
    "print(\"lightgbm mape:\", mape_by_month(y_test, gbm.predict(X_test_scaled)), gbm.best_params_)\n",
    "print(\"lightgbm rmse:\", rmse(y_test, gbm.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm mape: 78.07847265417618 {'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 170, 'num_leaves': 8}\n",
      "lightgbm rmse: 4406.06631028755\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled = diff_scale('norm', X_train, X_test)\n",
    "param_grid = {\n",
    "    'n_estimators' : list(range(100, 180,10)),\n",
    "    'num_leaves': list(range(7,10, 1)),\n",
    "    # 'min_data_in_leaf': [10, 20, 40, 60, 100],\n",
    "    'max_depth': [2, 4, 6, 7, 8],\n",
    "    'learning_rate': [0.01, .016, .02, .1, .2, .3]}\n",
    "    # 'bagging_freq': [3, 4, 5, 6, 7],\n",
    "    # 'bagging_fraction': np.linspace(0.6, 0.95, 10),\n",
    "    # 'reg_alpha': np.linspace(0.1, 0.95, 10),\n",
    "    # 'reg_lambda': np.linspace(0.1, 0.95, 10)\n",
    "\n",
    "    \n",
    "scorer = make_scorer(mape, greater_is_better = False)   \n",
    "gbm = GridSearchCV(lgb.LGBMRegressor(cat_features= cat_var), \n",
    "                   param_grid, \n",
    "                   scoring = scorer, \n",
    "                   n_jobs = -2,\n",
    "                   cv = GroupKFold(n_splits=10))\n",
    "\n",
    "\n",
    "gbm.fit(X_train_scaled, y_train, groups=groups)\n",
    "\n",
    "print(\"lightgbm mape:\", mape_by_month(y_test, gbm.predict(X_test_scaled)), gbm.best_params_)\n",
    "print(\"lightgbm rmse:\", rmse(y_test, gbm.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tuning another parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm mape: 77.65397911725476 {'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 170, 'num_leaves': 9, 'reg_alpha': 0.1, 'reg_lambda': 0.3833333333333333}\n",
      "lightgbm rmse: 4364.7998910684055\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled = diff_scale('norm', X_train, X_test)\n",
    "param_grid = {\n",
    "    'n_estimators' : [170],\n",
    "    'num_leaves': [9],\n",
    "    # 'min_data_in_leaf': [10, 20, 40, 60, 100],\n",
    "    'max_depth': [7],\n",
    "    'learning_rate': [.2],\n",
    "    # 'bagging_freq': [3, 4, 5, 6, 7],\n",
    "    # 'bagging_fraction': np.linspace(0.6, 0.95, 10),\n",
    "    'reg_alpha': np.linspace(0.1, 0.95, 10),\n",
    "    'reg_lambda': np.linspace(0.1, 0.95, 10)}\n",
    "\n",
    "    \n",
    "scorer = make_scorer(mape, greater_is_better = False)   \n",
    "gbm = GridSearchCV(lgb.LGBMRegressor(cat_features= cat_var), \n",
    "                   param_grid, \n",
    "                   scoring = scorer, \n",
    "                   n_jobs = -2,\n",
    "                   cv = GroupKFold(n_splits=5))\n",
    "\n",
    "\n",
    "gbm.fit(X_train_scaled, y_train, groups=groups)\n",
    "print(\"lightgbm mape:\", mape_by_month(y_test, gbm.predict(X_test_scaled)), gbm.best_params_)\n",
    "print(\"lightgbm rmse:\", rmse(y_test, gbm.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm mape: 77.83103272916486 {'learning_rate': 0.2, 'max_depth': 7, 'min_data_in_leaf': 10, 'n_estimators': 170, 'num_leaves': 9, 'reg_alpha': 0.7222222222222222, 'reg_lambda': 0.2777777777777778}\n",
      "lightgbm rmse: 4349.254952177309\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled = diff_scale('norm', X_train, X_test)\n",
    "param_grid = {\n",
    "    'n_estimators' : [170],\n",
    "    'num_leaves': [9],\n",
    "    'min_data_in_leaf': [10, 20, 40, 60, 100],\n",
    "    'max_depth': [7],\n",
    "    'learning_rate': [.2],\n",
    "    # 'bagging_freq': [3, 4, 5, 6, 7],\n",
    "    # 'bagging_fraction': np.linspace(0.6, 0.95, 10),\n",
    "    'reg_alpha': np.linspace(0.1, .9, 10),\n",
    "    'reg_lambda': np.linspace(0.1, 0.9, 10)}\n",
    "\n",
    "    \n",
    "scorer = make_scorer(mape, greater_is_better = False)   \n",
    "gbm = GridSearchCV(lgb.LGBMRegressor(cat_features= cat_var), \n",
    "                   param_grid, \n",
    "                   scoring = scorer, \n",
    "                   n_jobs = -2,\n",
    "                   cv = GroupKFold(n_splits=5))\n",
    "\n",
    "\n",
    "gbm.fit(X_train_scaled, y_train, groups=groups)\n",
    "print(\"lightgbm mape:\", mape_by_month(y_test, gbm.predict(X_test_scaled)), gbm.best_params_)\n",
    "print(\"lightgbm rmse:\", rmse(y_test, gbm.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 45 candidates, totalling 450 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 11 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  19 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=-2)]: Done 140 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-2)]: Done 343 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-2)]: Done 450 out of 450 | elapsed:  8.0min finished\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB mape: 77.30885861479051 {'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 200}\n",
      "XGB rmse: 4324.4381240720095\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators' : list(range(150, 400, 50)),\n",
    "    # 'num_leaves': list(range(8, 16, 4)),\n",
    "    # 'min_data_in_leaf': [10, 20, 40, 60, 100],\n",
    "    'max_depth': [8, 12, 15],\n",
    "    'learning_rate': [.3, 0.1, 0.01]}\n",
    "    # 'bagging_freq': [3, 4, 5, 6, 7],\n",
    "    # 'bagging_fraction': np.linspace(0.6, 0.95, 10),\n",
    "    # 'reg_alpha': np.linspace(0.1, 0.95, 10),\n",
    "    # 'reg_lambda': np.linspace(0.1, 0.95, 10)\n",
    "                          \n",
    "scorer = make_scorer(mape, greater_is_better = False) \n",
    "model_xgb = xgb.XGBRegressor(objective = 'reg:squarederror')                        \n",
    "\n",
    "    \n",
    "grid_xgb = GridSearchCV(model_xgb, \n",
    "                        param_grid, \n",
    "                        scoring = scorer,\n",
    "                        n_jobs=-2,\n",
    "                        verbose=2,\n",
    "                        cv = GroupKFold(n_splits=10))\n",
    "\n",
    "grid_xgb.fit(X_train_scaled, y_train, groups = groups)\n",
    "\n",
    "print(\"XGB mape:\", mape_by_month(y_test, grid_xgb.predict(X_test_scaled)), grid_xgb.best_params_)\n",
    "print(\"XGB rmse:\", rmse(y_test, grid_xgb.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 11 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  19 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=-2)]: Done  90 out of  90 | elapsed:   47.7s finished\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB mape: 77.30885861479051 {'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 200, 'num_leaves': 8}\n",
      "XGB rmse: 4324.4381240720095\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators' : [200],\n",
    "    'num_leaves': list(range(8, 17, 3)),\n",
    "    # 'min_data_in_leaf': [10, 20, 40, 60, 100],\n",
    "    'max_depth': [8, 9],\n",
    "    'learning_rate': [.09, .1, 0.15]}\n",
    "    # 'bagging_freq': [3, 4, 5, 6, 7],\n",
    "    # 'bagging_fraction': np.linspace(0.6, 0.95, 10),\n",
    "    # 'reg_alpha': np.linspace(0.1, 0.95, 10),\n",
    "    # 'reg_lambda': np.linspace(0.1, 0.95, 10)\n",
    "                          \n",
    "scorer = make_scorer(mape, greater_is_better = False) \n",
    "model_xgb_1 = xgb.XGBRegressor(objective = 'reg:squarederror')                        \n",
    "\n",
    "    \n",
    "model_xgb_1 = GridSearchCV(model_xgb, \n",
    "                        param_grid, \n",
    "                        scoring = scorer,\n",
    "                        n_jobs=-2,\n",
    "                        verbose=2,\n",
    "                        cv = GroupKFold(n_splits=5))\n",
    "\n",
    "grid_xgb_1.fit(X_train_scaled, y_train, groups = groups)\n",
    "\n",
    "print(\"XGB mape:\", mape_by_month(y_test, model_xgb_1.predict(X_test_scaled)), model_xgb_1.best_params_)\n",
    "print(\"XGB rmse:\", rmse(y_test, model_xgb_1.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 11 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  19 tasks      | elapsed:   10.1s\n",
      "[Parallel(n_jobs=-2)]: Done 140 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-2)]: Done 343 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-2)]: Done 626 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:  9.6min finished\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB mape: 77.30885861479051 {'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 200, 'num_leaves': 8, 'reg_alpha': 0.28888888888888886, 'reg_lambda': 0.5722222222222222}\n",
      "XGB rmse: 4324.4381240720095\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators' : [200],\n",
    "    'num_leaves': [8],\n",
    "    # 'min_data_in_leaf': [10, 20, 40, 60, 100],\n",
    "    'max_depth': [8, 9],\n",
    "    'learning_rate': [.1],\n",
    "    # 'bagging_freq': [3, 4, 5, 6, 7],\n",
    "    # 'bagging_fraction': np.linspace(0.6, 0.95, 10),\n",
    "    'reg_alpha': np.linspace(0.1, 0.95, 10),\n",
    "    'reg_lambda': np.linspace(0.1, 0.95, 10)}\n",
    "                          \n",
    "scorer = make_scorer(mape, greater_is_better = False) \n",
    "model_xgb_2 = xgb.XGBRegressor(objective = 'reg:squarederror')                        \n",
    "\n",
    "    \n",
    "model_xgb_2 = GridSearchCV(model_xgb, \n",
    "                        param_grid, \n",
    "                        scoring = scorer,\n",
    "                        n_jobs=-2,\n",
    "                        verbose=2,\n",
    "                        cv = GroupKFold(n_splits=5))\n",
    "\n",
    "model_xgb_2.fit(X_train_scaled, y_train, groups = groups)\n",
    "\n",
    "print(\"XGB mape:\", mape_by_month(y_test, model_xgb_2.predict(X_test_scaled)), model_xgb_2.best_params_)\n",
    "print(\"XGB rmse:\", rmse(y_test, model_xgb_2.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### try to use simple CV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 11 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  19 tasks      | elapsed:   14.8s\n",
      "[Parallel(n_jobs=-2)]: Done 140 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-2)]: Done 343 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-2)]: Done 626 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-2)]: Done 1000 out of 1000 | elapsed:  9.9min finished\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB mape: 77.18610178943412 {'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 200, 'num_leaves': 8, 'reg_alpha': 0.8555555555555555, 'reg_lambda': 0.95}\n",
      "XGB rmse: 4330.045389777716\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators' : [200],\n",
    "    'num_leaves': [8],\n",
    "    # 'min_data_in_leaf': [10, 20, 40, 60, 100],\n",
    "    'max_depth': [8, 9],\n",
    "    'learning_rate': [.1],\n",
    "    # 'bagging_freq': [3, 4, 5, 6, 7],\n",
    "    # 'bagging_fraction': np.linspace(0.6, 0.95, 10),\n",
    "    'reg_alpha': np.linspace(0.1, 0.95, 10),\n",
    "    'reg_lambda': np.linspace(0.1, 0.95, 10)}\n",
    "                          \n",
    "scorer = make_scorer(mape, greater_is_better = False) \n",
    "model_xgb = xgb.XGBRegressor(objective = 'reg:squarederror')                        \n",
    "\n",
    "    \n",
    "grid_xgb_3 = GridSearchCV(model_xgb, \n",
    "                        param_grid, \n",
    "                        scoring = scorer,\n",
    "                        n_jobs=-2,\n",
    "                        verbose=2,\n",
    "                        cv = 5)\n",
    "\n",
    "grid_xgb_3.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"XGB mape:\", mape_by_month(y_test, grid_xgb_3.predict(X_test_scaled)), grid_xgb_3.best_params_)\n",
    "print(\"XGB rmse:\", rmse(y_test, grid_xgb_3.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB mape: 77.18610178943412\n",
      "XGB rmse: 4330.045389777716\n"
     ]
    }
   ],
   "source": [
    "# use parametesr into models:\n",
    "grid_xgb_result = xgb.XGBRegressor(objective = 'reg:squarederror', max_depth=9, n_estimators=200, learning_rate=0.1, num_leaves=8, reg_alpha=0.8555555555555555, reg_lambda=0.95).fit(X_train_scaled, y_train)\n",
    "print(\"XGB mape:\", mape_by_month(y_test, grid_xgb_result.predict(X_test_scaled)))\n",
    "print(\"XGB rmse:\", rmse(y_test, grid_xgb_result.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (1248,56) and (58,) not aligned: 56 (dim 1) != 58 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-649-6f9b3c7a11b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mridge_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    455\u001b[0m         \"\"\"\n\u001b[0;32m    456\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'predict'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'best_estimator_'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'estimator'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    219\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m         \"\"\"\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'csc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'coo'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[1;32m--> 206\u001b[1;33m                                dense_output=True) + self.intercept_\n\u001b[0m\u001b[0;32m    207\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (1248,56) and (58,) not aligned: 56 (dim 1) != 58 (dim 0)"
     ]
    }
   ],
   "source": [
    "ridge_cv.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55']\nexpected f56 in input data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-654-7b6e7468ff62>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m pd.DataFrame(grid_xgb_result.predict(X_test_scaled),\n\u001b[0m\u001b[0;32m      2\u001b[0m             \u001b[0mgbm_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m             ridge_cv.predict(X_test_scaled))\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, output_margin, ntree_limit, validate_features)\u001b[0m\n\u001b[0;32m    454\u001b[0m                                           \u001b[0moutput_margin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m                                           \u001b[0mntree_limit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mntree_limit\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 456\u001b[1;33m                                           validate_features=validate_features)\n\u001b[0m\u001b[0;32m    457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntree_limit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features)\u001b[0m\n\u001b[0;32m   1282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1283\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvalidate_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1284\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1286\u001b[0m         \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_bst_ulong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_validate_features\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1689\u001b[0m                 raise ValueError(msg.format(self.feature_names,\n\u001b[1;32m-> 1690\u001b[1;33m                                             data.feature_names))\n\u001b[0m\u001b[0;32m   1691\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1692\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_split_value_histogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_pandas\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: feature_names mismatch: ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55', 'f56'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33', 'f34', 'f35', 'f36', 'f37', 'f38', 'f39', 'f40', 'f41', 'f42', 'f43', 'f44', 'f45', 'f46', 'f47', 'f48', 'f49', 'f50', 'f51', 'f52', 'f53', 'f54', 'f55']\nexpected f56 in input data"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(grid_xgb_result.predict(X_test_scaled),\n",
    "            gbm_1.predict(X_test_scaled),\n",
    "            ridge_cv.predict(X_test_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingRegressor(meta_regressor=GridSearchCV(cv='warn',\n",
       "                                              error_score='raise-deprecating',\n",
       "                                              estimator=Ridge(alpha=1.0,\n",
       "                                                              copy_X=True,\n",
       "                                                              fit_intercept=True,\n",
       "                                                              max_iter=None,\n",
       "                                                              normalize=False,\n",
       "                                                              random_state=None,\n",
       "                                                              solver='auto',\n",
       "                                                              tol=0.001),\n",
       "                                              iid='warn', n_jobs=-2,\n",
       "                                              param_grid={'alpha': array([0.  , 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1 ,\n",
       "       0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0....\n",
       "                                                         tol=0.001,\n",
       "                                                         verbose=False),\n",
       "                                           iid='warn', n_jobs=-2,\n",
       "                                           param_grid={'C': [1, 2, 4, 5],\n",
       "                                                       'epsilon': [0.3, 0.35,\n",
       "                                                                   0.45, 0.5],\n",
       "                                                       'gamma': [1e-10, 1e-09,\n",
       "                                                                 1e-08, 1e-07],\n",
       "                                                       'kernel': ['linear']},\n",
       "                                           pre_dispatch='2*n_jobs', refit=True,\n",
       "                                           return_train_score=False,\n",
       "                                           scoring=make_scorer(mape, greater_is_better=False),\n",
       "                                           verbose=0)],\n",
       "                  store_train_meta_features=False,\n",
       "                  use_features_in_secondary=True, verbose=0)"
      ]
     },
     "execution_count": 642,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn linear_model\n",
    "stacker= linear_model.LinearRegression()\n",
    "stacker.fit(pd.DataFrame(grid_xgb_result.predict(X_test_scaled),\n",
    "            gbm_1.predict(X_test_scaled),\n",
    "            ridge_cv.predict(X_test_scaled)),\n",
    "            X_test_scaled)\n",
    "\n",
    "print(\"stacker mape:\", mape_by_month(y_test, stregr.predict(X_test_scaled)))\n",
    "print(\"stacker rmse:\", rmse(y_test, stregr.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mlxtend:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB mape: 77.13224507532261\n",
      "XGB rmse: 4326.8949875543485\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.regressor import StackingRegressor\n",
    "\n",
    "stregr_1 = StackingRegressor(regressors=[gbm_g1_result, grid_xgb_result, svr], \n",
    "                           meta_regressor=ridge_cv)\n",
    "\n",
    "stregr_1.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"stregr_1 mape:\", mape_by_month(y_test, stregr.predict(X_test_scaled)))\n",
    "print(\"stregr_1 rmse:\", rmse(y_test, stregr.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stregr_1 mape: 77.15165151557427\n",
      "stregr_1 rmse: 4327.477517306288\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.regressor import StackingRegressor\n",
    "\n",
    "stregr_1 = StackingRegressor(regressors=[gbm_g1_result, grid_xgb_result, svr], \n",
    "                             meta_regressor=ridge_cv,\n",
    "                             use_features_in_secondary=True)\n",
    "\n",
    "stregr_1.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"stregr_1 mape:\", mape_by_month(y_test, stregr.predict(X_test_scaled)))\n",
    "print(\"stregr_1 rmse:\", rmse(y_test, stregr.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### w/o SVR:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB mape: 77.15165151557427\n",
      "XGB rmse: 4327.477517306288\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.regressor import StackingRegressor\n",
    "\n",
    "stregr_2 = StackingRegressor(regressors=[gbm_g1_result, grid_xgb_result], \n",
    "                           meta_regressor=ridge_cv)\n",
    "\n",
    "stregr_2.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"stregr_2 mape:\", mape_by_month(y_test, stregr_2.predict(X_test_scaled)))\n",
    "print(\"stregr_2 rmse:\", rmse(y_test, stregr_2.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stregr_2 mape: 77.10670822781684\n",
      "stregr_2 rmse: 4327.203301896387\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.regressor import StackingRegressor\n",
    "\n",
    "stregr_2 = StackingRegressor(regressors=[gbm_g1_result, grid_xgb_result], \n",
    "                             meta_regressor=ridge_cv,\n",
    "                             use_features_in_secondary=True)\n",
    "\n",
    "stregr_2.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"stregr_2 mape:\", mape_by_month(y_test, stregr_2.predict(X_test_scaled)))\n",
    "print(\"stregr_2 rmse:\", rmse(y_test, stregr_2.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### w/o SVR & use_features_in_secondary=True:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stregr_2 mape: 77.10670822781684\n",
      "stregr_2 rmse: 4327.203301896387\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.regressor import StackingRegressor\n",
    "\n",
    "stregr_2 = StackingRegressor(regressors=[gbm_g1_result, grid_xgb_result], \n",
    "                            meta_regressor=ridge_cv)\n",
    "\n",
    "stregr_2.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"stregr_2 mape:\", mape_by_month(y_test, stregr_2.predict(X_test_scaled)))\n",
    "print(\"stregr_2 rmse:\", rmse(y_test, stregr_2.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stregr_3 mape: 76.49314308564793\n",
      "stregr_3 rmse: 4260.199986596819\n"
     ]
    }
   ],
   "source": [
    "stregr_3 = StackingRegressor(regressors=[ridge_cv, grid_xgb_result], \n",
    "                            meta_regressor=gbm_g1_result,\n",
    "                            use_features_in_secondary=True)\n",
    "\n",
    "stregr_3.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"stregr_3 mape:\", mape_by_month(y_test, stregr_3.predict(X_test_scaled)))\n",
    "print(\"stregr_3 rmse:\", rmse(y_test, stregr_3.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all models, but meta_regressor = lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stregr_3 mape: 76.4909991551237\n",
      "stregr_3 rmse: 4260.9201545274855\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.regressor import StackingRegressor\n",
    "\n",
    "stregr_3 = StackingRegressor(regressors=[ridge_cv, grid_xgb_result, svr], \n",
    "                            meta_regressor=gbm_g1_result)\n",
    "\n",
    "stregr_3.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"stregr_3 mape:\", mape_by_month(y_test, stregr_3.predict(X_test_scaled)))\n",
    "print(\"stregr_3 rmse:\", rmse(y_test, stregr_3.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all models, but meta_regressor = lightgbm & use_features_in_secondary=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB mape: 76.42096805754505\n",
      "XGB rmse: 4258.359350488903\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.regressor import StackingRegressor\n",
    "\n",
    "stregr_3 = StackingRegressor(regressors=[ridge_cv, grid_xgb_result, svr], \n",
    "                            meta_regressor=gbm_g1_result,\n",
    "                            use_features_in_secondary=True)\n",
    "\n",
    "stregr_3.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"stregr_3 mape:\", mape_by_month(y_test, stregr_3.predict(X_test_scaled)))\n",
    "print(\"stregr_3 rmse:\", rmse(y_test, stregr_3.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TPOT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTRegressor\n",
    "from tpot.builtins import StackingEstimator\n",
    "from sklearn.pipeline import make_pipeline, make_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=450, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: -1250958.359196122\n",
      "Generation 2 - Current best internal CV score: -1250958.359196122\n",
      "Generation 3 - Current best internal CV score: -1250958.359196122\n",
      "Generation 4 - Current best internal CV score: -1250958.359196122\n",
      "Generation 5 - Current best internal CV score: -1247403.7385499007\n",
      "Generation 6 - Current best internal CV score: -1246578.0061185411\n",
      "Generation 7 - Current best internal CV score: -1245702.6176878647\n",
      "Generation 8 - Current best internal CV score: -1245499.7739479125\n",
      "\n",
      "Best pipeline: ExtraTreesRegressor(ZeroCount(ElasticNetCV(LassoLarsCV(Normalizer(ElasticNetCV(input_matrix, l1_ratio=0.6000000000000001, tol=0.01), norm=l1), normalize=False), l1_ratio=0.6000000000000001, tol=0.01)), bootstrap=True, max_features=0.2, min_samples_leaf=10, min_samples_split=4, n_estimators=100)\n",
      "-19456399.769313164\n"
     ]
    }
   ],
   "source": [
    "tpot = TPOTRegressor(generations=8, population_size=50, verbosity=2)\n",
    "tpot.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"stregr_3 mape:\", mape_by_month(y_test, tpot.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tpot mape: 78.09983868224177\n"
     ]
    }
   ],
   "source": [
    "print(\"tpot mape:\", mape_by_month(y_test, tpot.predict(X_test_scaled)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use only StackingEstimator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tpot mape: 76.33902460458779\n"
     ]
    }
   ],
   "source": [
    "exported_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=ridge_cv),\n",
    "    gbm_g1_result)\n",
    "\n",
    "exported_pipeline.fit(X_train_scaled, y_train)\n",
    "results = exported_pipeline.predict(X_test_scaled)\n",
    "print(\"tpot mape:\", mape_by_month(y_test, results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tpot mape: 76.41617182539356\n"
     ]
    }
   ],
   "source": [
    "exported_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=grid_xgb_result),\n",
    "    gbm_g1_result)\n",
    "\n",
    "exported_pipeline.fit(X_train_scaled, y_train)\n",
    "results = exported_pipeline.predict(X_test_scaled)\n",
    "print(\"tpot mape:\", mape_by_month(y_test, results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-632-12f93621d76d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     gbm_g1_result)\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mexported_pipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexported_pipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tpot mape:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmape_by_month\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    350\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m         \"\"\"\n\u001b[1;32m--> 352\u001b[1;33m         \u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m         with _print_elapsed_time('Pipeline',\n\u001b[0;32m    354\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    315\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Pipeline'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m                 **fit_params_steps[name])\n\u001b[0m\u001b[0;32m    318\u001b[0m             \u001b[1;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m             \u001b[1;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    714\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 556\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tpot\\builtins\\stacking_estimator.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \"\"\"\n\u001b[1;32m---> 67\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    685\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 687\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1146\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1147\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1148\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    664\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 666\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    667\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    668\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 934\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    935\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    936\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    831\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    832\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 833\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    834\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    835\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    519\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    520\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    425\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 427\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "exported_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=grid_xgb_result),\n",
    "    StackingEstimator(estimator=ridge_cv),\n",
    "    StackingEstimator(estimator=svr),\n",
    "    gbm_g1_result)\n",
    "\n",
    "exported_pipeline.fit(X_train_scaled, y_train)\n",
    "results = exported_pipeline.predict(X_test_scaled)\n",
    "print(\"tpot mape:\", mape_by_month(y_test, results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tpot mape: 76.1833432870904\n"
     ]
    }
   ],
   "source": [
    "exported_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=ridge_cv),\n",
    "    StackingEstimator(estimator=grid_xgb_result),\n",
    "    gbm_g1_result)\n",
    "\n",
    "exported_pipeline.fit(X_train_scaled, y_train)\n",
    "results = exported_pipeline.predict(X_test_scaled)\n",
    "print(\"tpot mape:\", mape_by_month(y_test, results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\xgboost\\core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tpot mape: 76.53996226486204\n"
     ]
    }
   ],
   "source": [
    "# 77.106\n",
    "exported_pipeline = make_pipeline(\n",
    "    StackingEstimator(estimator=gbm_g1_result),\n",
    "    StackingEstimator(estimator=grid_xgb_result),\n",
    "    ridge_cv)\n",
    "\n",
    "exported_pipeline.fit(X_train_scaled, y_train)\n",
    "results = exported_pipeline.predict(X_test_scaled)\n",
    "print(\"tpot mape:\", mape_by_month(y_test, results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5992973208205112\n",
      "2.3539111203391774\n",
      "2311.4984864314583\n"
     ]
    }
   ],
   "source": [
    "test2 = test.copy()\n",
    "test2['y_pred'] = np.array(ridge_cv.predict(X_test_scaled))\n",
    "test2['Customer_SKU'] = test2.merge(data_labels, left_index=True, right_index=True)['SKU_Customer']\n",
    "test2['y_pred'] = np.array(test2.groupby(['Customer_SKU', 'Year', 'Month_No', ]).y_pred.transform('sum'))\n",
    "\n",
    "final_data = test2[['Sales', 'y_pred', 'Customer_SKU', 'Year', 'Month_No']]\n",
    "final_data = final_data.drop_duplicates()\n",
    "\n",
    "\n",
    "final_data['MAD'] = np.where((final_data['y_pred'] == 0)&(final_data['Sales'] == 0), 0, \\\n",
    "                           np.where((final_data['y_pred'] == 0)&(final_data['Sales']!=0),1, np.abs(final_data['y_pred']-final_data['Sales'])/final_data['y_pred']))\n",
    " \n",
    "final_data['MAPE'] = np.where((final_data['y_pred'] == 0)&(final_data['Sales'] == 0), 0, \\\n",
    "                           np.where((final_data['y_pred'] != 0)&(final_data['Sales']==0),1, np.abs(final_data['y_pred']-final_data['Sales'])/final_data['Sales']))\n",
    "\n",
    "    \n",
    "print(final_data['MAD'].mean())   \n",
    "print(final_data['MAPE'].mean())     \n",
    "print(rmse_by_month(final_data['Sales'], final_data['y_pred']))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>SKU_Customer</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month_No</th>\n",
       "      <th>MAD</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>908.00</td>\n",
       "      <td>1355.940948</td>\n",
       "      <td>ALL OTHERS - US62338-91101</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>0.330354</td>\n",
       "      <td>0.493327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>884.00</td>\n",
       "      <td>1307.660955</td>\n",
       "      <td>ALL OTHERS - US62338-91101</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>0.323984</td>\n",
       "      <td>0.479254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>204</td>\n",
       "      <td>1433.40</td>\n",
       "      <td>1344.623901</td>\n",
       "      <td>ALL OTHERS - US62338-91101</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>0.066023</td>\n",
       "      <td>0.061934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>209</td>\n",
       "      <td>971.75</td>\n",
       "      <td>1327.359232</td>\n",
       "      <td>ALL OTHERS - US62338-91101</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>0.267907</td>\n",
       "      <td>0.365947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>213</td>\n",
       "      <td>1041.75</td>\n",
       "      <td>1335.907865</td>\n",
       "      <td>ALL OTHERS - US62338-91101</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>0.220193</td>\n",
       "      <td>0.282369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14962</td>\n",
       "      <td>5861.00</td>\n",
       "      <td>3817.674067</td>\n",
       "      <td>WALMART US19200-79329</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>0.535228</td>\n",
       "      <td>0.348631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14967</td>\n",
       "      <td>9319.00</td>\n",
       "      <td>3800.409398</td>\n",
       "      <td>WALMART US19200-79329</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1.452104</td>\n",
       "      <td>0.592187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14971</td>\n",
       "      <td>835.00</td>\n",
       "      <td>3808.958031</td>\n",
       "      <td>WALMART US19200-79329</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>0.780780</td>\n",
       "      <td>3.561626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14975</td>\n",
       "      <td>3230.60</td>\n",
       "      <td>3845.920978</td>\n",
       "      <td>WALMART US19200-79329</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>0.159993</td>\n",
       "      <td>0.190466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14980</td>\n",
       "      <td>554.50</td>\n",
       "      <td>3743.449278</td>\n",
       "      <td>WALMART US19200-79329</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>0.851875</td>\n",
       "      <td>5.751036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>336 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Sales       y_pred                SKU_Customer  Year  Month_No  \\\n",
       "198     908.00  1355.940948  ALL OTHERS - US62338-91101  2018        10   \n",
       "200     884.00  1307.660955  ALL OTHERS - US62338-91101  2018        11   \n",
       "204    1433.40  1344.623901  ALL OTHERS - US62338-91101  2018        12   \n",
       "209     971.75  1327.359232  ALL OTHERS - US62338-91101  2019         1   \n",
       "213    1041.75  1335.907865  ALL OTHERS - US62338-91101  2019         2   \n",
       "...        ...          ...                         ...   ...       ...   \n",
       "14962  5861.00  3817.674067       WALMART US19200-79329  2018        12   \n",
       "14967  9319.00  3800.409398       WALMART US19200-79329  2019         1   \n",
       "14971   835.00  3808.958031       WALMART US19200-79329  2019         2   \n",
       "14975  3230.60  3845.920978       WALMART US19200-79329  2019         3   \n",
       "14980   554.50  3743.449278       WALMART US19200-79329  2019         4   \n",
       "\n",
       "            MAD      MAPE  \n",
       "198    0.330354  0.493327  \n",
       "200    0.323984  0.479254  \n",
       "204    0.066023  0.061934  \n",
       "209    0.267907  0.365947  \n",
       "213    0.220193  0.282369  \n",
       "...         ...       ...  \n",
       "14962  0.535228  0.348631  \n",
       "14967  1.452104  0.592187  \n",
       "14971  0.780780  3.561626  \n",
       "14975  0.159993  0.190466  \n",
       "14980  0.851875  5.751036  \n",
       "\n",
       "[336 rows x 7 columns]"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.to_csv('Final_result_for_weeks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pd.read_csv('Final_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x25280a17dd8>"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(final_data['Sales'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sales</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>SKU_Customer</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month_No</th>\n",
       "      <th>MAD</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>198</td>\n",
       "      <td>908.00</td>\n",
       "      <td>1355.940948</td>\n",
       "      <td>ALL OTHERS - US62338-91101</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>0.330354</td>\n",
       "      <td>0.493327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>884.00</td>\n",
       "      <td>1307.660955</td>\n",
       "      <td>ALL OTHERS - US62338-91101</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>0.323984</td>\n",
       "      <td>0.479254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>204</td>\n",
       "      <td>1433.40</td>\n",
       "      <td>1344.623901</td>\n",
       "      <td>ALL OTHERS - US62338-91101</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>0.066023</td>\n",
       "      <td>0.061934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>209</td>\n",
       "      <td>971.75</td>\n",
       "      <td>1327.359232</td>\n",
       "      <td>ALL OTHERS - US62338-91101</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>0.267907</td>\n",
       "      <td>0.365947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>213</td>\n",
       "      <td>1041.75</td>\n",
       "      <td>1335.907865</td>\n",
       "      <td>ALL OTHERS - US62338-91101</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>0.220193</td>\n",
       "      <td>0.282369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    Sales       y_pred                SKU_Customer  Year  \\\n",
       "0         198   908.00  1355.940948  ALL OTHERS - US62338-91101  2018   \n",
       "1         200   884.00  1307.660955  ALL OTHERS - US62338-91101  2018   \n",
       "2         204  1433.40  1344.623901  ALL OTHERS - US62338-91101  2018   \n",
       "3         209   971.75  1327.359232  ALL OTHERS - US62338-91101  2019   \n",
       "4         213  1041.75  1335.907865  ALL OTHERS - US62338-91101  2019   \n",
       "\n",
       "   Month_No       MAD      MAPE  \n",
       "0        10  0.330354  0.493327  \n",
       "1        11  0.323984  0.479254  \n",
       "2        12  0.066023  0.061934  \n",
       "3         1  0.267907  0.365947  \n",
       "4         2  0.220193  0.282369  "
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2528394b400>"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.kdeplot(final_data['Sales'])\n",
    "sns.kdeplot(final_data['y_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6068816887333172"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data[final_data['Sales']>2000].MAD.mean()\n",
    "final_data[final_data['Sales']<2000].MAD.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2772333413003364\n",
      "2.805362811434578\n"
     ]
    }
   ],
   "source": [
    "print(final_data[final_data['Sales']>1000].MAPE.mean())\n",
    "print(final_data[final_data['Sales']<1000].MAPE.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>SKU_Customer</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month_No</th>\n",
       "      <th>MAD</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>204</td>\n",
       "      <td>1433.40</td>\n",
       "      <td>1344.623901</td>\n",
       "      <td>ALL OTHERS - US62338-91101</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>0.066023</td>\n",
       "      <td>0.061934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>213</td>\n",
       "      <td>1041.75</td>\n",
       "      <td>1335.907865</td>\n",
       "      <td>ALL OTHERS - US62338-91101</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>0.220193</td>\n",
       "      <td>0.282369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>217</td>\n",
       "      <td>1023.80</td>\n",
       "      <td>1372.870812</td>\n",
       "      <td>ALL OTHERS - US62338-91101</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>0.254263</td>\n",
       "      <td>0.340956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>512</td>\n",
       "      <td>1648.50</td>\n",
       "      <td>1720.691652</td>\n",
       "      <td>ALL OTHERS - US62338-92944</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>0.041955</td>\n",
       "      <td>0.043792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>514</td>\n",
       "      <td>1587.50</td>\n",
       "      <td>1672.411659</td>\n",
       "      <td>ALL OTHERS - US62338-92944</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>0.050772</td>\n",
       "      <td>0.053488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>518</td>\n",
       "      <td>1372.00</td>\n",
       "      <td>1709.374605</td>\n",
       "      <td>ALL OTHERS - US62338-92944</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>0.197367</td>\n",
       "      <td>0.245900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>523</td>\n",
       "      <td>1527.75</td>\n",
       "      <td>1692.109936</td>\n",
       "      <td>ALL OTHERS - US62338-92944</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>0.097133</td>\n",
       "      <td>0.107583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>527</td>\n",
       "      <td>1004.25</td>\n",
       "      <td>1700.658569</td>\n",
       "      <td>ALL OTHERS - US62338-92944</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>0.409493</td>\n",
       "      <td>0.693461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>531</td>\n",
       "      <td>1280.60</td>\n",
       "      <td>1737.621515</td>\n",
       "      <td>ALL OTHERS - US62338-92944</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>0.263016</td>\n",
       "      <td>0.356881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>845</td>\n",
       "      <td>1980.80</td>\n",
       "      <td>433.093859</td>\n",
       "      <td>ALL OTHERS - US62338-99058</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>3.573604</td>\n",
       "      <td>0.781354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2396</td>\n",
       "      <td>1520.00</td>\n",
       "      <td>948.860714</td>\n",
       "      <td>DOLLAR GENERAL62338-92944</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>0.601921</td>\n",
       "      <td>0.375750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2398</td>\n",
       "      <td>1496.25</td>\n",
       "      <td>850.666543</td>\n",
       "      <td>DOLLAR GENERAL62338-92944</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>0.758915</td>\n",
       "      <td>0.431468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2402</td>\n",
       "      <td>1204.60</td>\n",
       "      <td>822.651496</td>\n",
       "      <td>DOLLAR GENERAL62338-92944</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>0.464290</td>\n",
       "      <td>0.317075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3024</td>\n",
       "      <td>2149.00</td>\n",
       "      <td>587.840448</td>\n",
       "      <td>DRUGSTORE62338-92944</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>2.655754</td>\n",
       "      <td>0.726459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3026</td>\n",
       "      <td>4449.50</td>\n",
       "      <td>509.105906</td>\n",
       "      <td>DRUGSTORE62338-92944</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>7.739832</td>\n",
       "      <td>0.885581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8054</td>\n",
       "      <td>1152.40</td>\n",
       "      <td>1074.483778</td>\n",
       "      <td>TARGET62338-99058</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>0.072515</td>\n",
       "      <td>0.067612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8067</td>\n",
       "      <td>1072.00</td>\n",
       "      <td>1129.626588</td>\n",
       "      <td>TARGET62338-99058</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>0.051014</td>\n",
       "      <td>0.053756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8676</td>\n",
       "      <td>1987.50</td>\n",
       "      <td>1985.799547</td>\n",
       "      <td>WALMART US62338-92944</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.000856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8678</td>\n",
       "      <td>1837.75</td>\n",
       "      <td>1699.434295</td>\n",
       "      <td>WALMART US62338-92944</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>0.081389</td>\n",
       "      <td>0.075264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8682</td>\n",
       "      <td>1686.40</td>\n",
       "      <td>1457.249969</td>\n",
       "      <td>WALMART US62338-92944</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>0.157248</td>\n",
       "      <td>0.135881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8687</td>\n",
       "      <td>2118.25</td>\n",
       "      <td>1564.488075</td>\n",
       "      <td>WALMART US62338-92944</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>0.353957</td>\n",
       "      <td>0.261424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8691</td>\n",
       "      <td>1730.75</td>\n",
       "      <td>1369.766141</td>\n",
       "      <td>WALMART US62338-92944</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>0.263537</td>\n",
       "      <td>0.208571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8695</td>\n",
       "      <td>1724.80</td>\n",
       "      <td>1593.184298</td>\n",
       "      <td>WALMART US62338-92944</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>0.082612</td>\n",
       "      <td>0.076308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8700</td>\n",
       "      <td>1325.50</td>\n",
       "      <td>1454.457709</td>\n",
       "      <td>WALMART US62338-92944</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>0.088664</td>\n",
       "      <td>0.097290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8990</td>\n",
       "      <td>2942.00</td>\n",
       "      <td>2913.516138</td>\n",
       "      <td>WALMART US62338-99058</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>0.009776</td>\n",
       "      <td>0.009682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8992</td>\n",
       "      <td>2497.25</td>\n",
       "      <td>2861.980094</td>\n",
       "      <td>WALMART US62338-99058</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>0.127440</td>\n",
       "      <td>0.146053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8996</td>\n",
       "      <td>2384.80</td>\n",
       "      <td>2659.147461</td>\n",
       "      <td>WALMART US62338-99058</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>0.103171</td>\n",
       "      <td>0.115040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9001</td>\n",
       "      <td>2962.25</td>\n",
       "      <td>2651.142856</td>\n",
       "      <td>WALMART US62338-99058</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>0.117348</td>\n",
       "      <td>0.105024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9005</td>\n",
       "      <td>2663.25</td>\n",
       "      <td>2633.571525</td>\n",
       "      <td>WALMART US62338-99058</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>0.011269</td>\n",
       "      <td>0.011144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9009</td>\n",
       "      <td>2652.40</td>\n",
       "      <td>2906.099439</td>\n",
       "      <td>WALMART US62338-99058</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>0.087299</td>\n",
       "      <td>0.095649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9014</td>\n",
       "      <td>2274.00</td>\n",
       "      <td>2761.941726</td>\n",
       "      <td>WALMART US62338-99058</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>0.176666</td>\n",
       "      <td>0.214574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9304</td>\n",
       "      <td>3699.50</td>\n",
       "      <td>4185.838930</td>\n",
       "      <td>ALL OTHERS - US51700-77050</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>0.116187</td>\n",
       "      <td>0.131461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9306</td>\n",
       "      <td>3182.75</td>\n",
       "      <td>4137.558937</td>\n",
       "      <td>ALL OTHERS - US51700-77050</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>0.230766</td>\n",
       "      <td>0.299995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9310</td>\n",
       "      <td>5027.40</td>\n",
       "      <td>4174.521883</td>\n",
       "      <td>ALL OTHERS - US51700-77050</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>0.204306</td>\n",
       "      <td>0.169646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9315</td>\n",
       "      <td>3130.00</td>\n",
       "      <td>4157.257214</td>\n",
       "      <td>ALL OTHERS - US51700-77050</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>0.247100</td>\n",
       "      <td>0.328197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9319</td>\n",
       "      <td>3861.25</td>\n",
       "      <td>4165.805847</td>\n",
       "      <td>ALL OTHERS - US51700-77050</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>0.073109</td>\n",
       "      <td>0.078875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9323</td>\n",
       "      <td>4284.60</td>\n",
       "      <td>4202.768794</td>\n",
       "      <td>ALL OTHERS - US51700-77050</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>0.019471</td>\n",
       "      <td>0.019099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9328</td>\n",
       "      <td>2269.00</td>\n",
       "      <td>4100.297094</td>\n",
       "      <td>ALL OTHERS - US51700-77050</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>0.446625</td>\n",
       "      <td>0.807094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10880</td>\n",
       "      <td>1500.80</td>\n",
       "      <td>881.324553</td>\n",
       "      <td>KROGER51700-77050</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>0.702891</td>\n",
       "      <td>0.412763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11816</td>\n",
       "      <td>2845.00</td>\n",
       "      <td>3087.112347</td>\n",
       "      <td>WALMART US51700-77050</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>0.078427</td>\n",
       "      <td>0.085101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11818</td>\n",
       "      <td>2896.75</td>\n",
       "      <td>3128.892558</td>\n",
       "      <td>WALMART US51700-77050</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>0.074193</td>\n",
       "      <td>0.080139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11822</td>\n",
       "      <td>2906.00</td>\n",
       "      <td>3169.340551</td>\n",
       "      <td>WALMART US51700-77050</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>0.083090</td>\n",
       "      <td>0.090620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11827</td>\n",
       "      <td>3201.75</td>\n",
       "      <td>3300.766460</td>\n",
       "      <td>WALMART US51700-77050</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>0.029998</td>\n",
       "      <td>0.030926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11831</td>\n",
       "      <td>2841.75</td>\n",
       "      <td>3281.084063</td>\n",
       "      <td>WALMART US51700-77050</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>0.133899</td>\n",
       "      <td>0.154600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11835</td>\n",
       "      <td>3076.20</td>\n",
       "      <td>3208.388051</td>\n",
       "      <td>WALMART US51700-77050</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>0.041201</td>\n",
       "      <td>0.042971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11840</td>\n",
       "      <td>2070.50</td>\n",
       "      <td>2993.599701</td>\n",
       "      <td>WALMART US51700-77050</td>\n",
       "      <td>2019</td>\n",
       "      <td>4</td>\n",
       "      <td>0.308358</td>\n",
       "      <td>0.445834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12130</td>\n",
       "      <td>1657.00</td>\n",
       "      <td>1987.576314</td>\n",
       "      <td>ALL OTHERS - US19200-79329</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>0.166321</td>\n",
       "      <td>0.199503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12132</td>\n",
       "      <td>1318.00</td>\n",
       "      <td>1939.296321</td>\n",
       "      <td>ALL OTHERS - US19200-79329</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>0.320372</td>\n",
       "      <td>0.471393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12136</td>\n",
       "      <td>2183.00</td>\n",
       "      <td>1976.259267</td>\n",
       "      <td>ALL OTHERS - US19200-79329</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>0.104612</td>\n",
       "      <td>0.094705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12141</td>\n",
       "      <td>1561.75</td>\n",
       "      <td>1958.994598</td>\n",
       "      <td>ALL OTHERS - US19200-79329</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>0.202780</td>\n",
       "      <td>0.254359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12145</td>\n",
       "      <td>2035.50</td>\n",
       "      <td>1967.543231</td>\n",
       "      <td>ALL OTHERS - US19200-79329</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>0.034539</td>\n",
       "      <td>0.033386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12149</td>\n",
       "      <td>2387.40</td>\n",
       "      <td>2004.506177</td>\n",
       "      <td>ALL OTHERS - US19200-79329</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>0.191017</td>\n",
       "      <td>0.160381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12760</td>\n",
       "      <td>1200.25</td>\n",
       "      <td>724.293886</td>\n",
       "      <td>DRUGSTORE19200-79329</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>0.657131</td>\n",
       "      <td>0.396547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12764</td>\n",
       "      <td>1661.20</td>\n",
       "      <td>761.256832</td>\n",
       "      <td>DRUGSTORE19200-79329</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>1.182181</td>\n",
       "      <td>0.541743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12769</td>\n",
       "      <td>1214.75</td>\n",
       "      <td>743.992163</td>\n",
       "      <td>DRUGSTORE19200-79329</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>0.632746</td>\n",
       "      <td>0.387535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14956</td>\n",
       "      <td>1302.00</td>\n",
       "      <td>3828.991114</td>\n",
       "      <td>WALMART US19200-79329</td>\n",
       "      <td>2018</td>\n",
       "      <td>10</td>\n",
       "      <td>0.659963</td>\n",
       "      <td>1.940853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14958</td>\n",
       "      <td>2577.50</td>\n",
       "      <td>3780.711121</td>\n",
       "      <td>WALMART US19200-79329</td>\n",
       "      <td>2018</td>\n",
       "      <td>11</td>\n",
       "      <td>0.318250</td>\n",
       "      <td>0.466813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14962</td>\n",
       "      <td>5861.00</td>\n",
       "      <td>3817.674067</td>\n",
       "      <td>WALMART US19200-79329</td>\n",
       "      <td>2018</td>\n",
       "      <td>12</td>\n",
       "      <td>0.535228</td>\n",
       "      <td>0.348631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14967</td>\n",
       "      <td>9319.00</td>\n",
       "      <td>3800.409398</td>\n",
       "      <td>WALMART US19200-79329</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1.452104</td>\n",
       "      <td>0.592187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14975</td>\n",
       "      <td>3230.60</td>\n",
       "      <td>3845.920978</td>\n",
       "      <td>WALMART US19200-79329</td>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>0.159993</td>\n",
       "      <td>0.190466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Sales       y_pred                SKU_Customer  Year  Month_No  \\\n",
       "204    1433.40  1344.623901  ALL OTHERS - US62338-91101  2018        12   \n",
       "213    1041.75  1335.907865  ALL OTHERS - US62338-91101  2019         2   \n",
       "217    1023.80  1372.870812  ALL OTHERS - US62338-91101  2019         3   \n",
       "512    1648.50  1720.691652  ALL OTHERS - US62338-92944  2018        10   \n",
       "514    1587.50  1672.411659  ALL OTHERS - US62338-92944  2018        11   \n",
       "518    1372.00  1709.374605  ALL OTHERS - US62338-92944  2018        12   \n",
       "523    1527.75  1692.109936  ALL OTHERS - US62338-92944  2019         1   \n",
       "527    1004.25  1700.658569  ALL OTHERS - US62338-92944  2019         2   \n",
       "531    1280.60  1737.621515  ALL OTHERS - US62338-92944  2019         3   \n",
       "845    1980.80   433.093859  ALL OTHERS - US62338-99058  2019         3   \n",
       "2396   1520.00   948.860714   DOLLAR GENERAL62338-92944  2018        10   \n",
       "2398   1496.25   850.666543   DOLLAR GENERAL62338-92944  2018        11   \n",
       "2402   1204.60   822.651496   DOLLAR GENERAL62338-92944  2018        12   \n",
       "3024   2149.00   587.840448        DRUGSTORE62338-92944  2018        10   \n",
       "3026   4449.50   509.105906        DRUGSTORE62338-92944  2018        11   \n",
       "8054   1152.40  1074.483778           TARGET62338-99058  2018        12   \n",
       "8067   1072.00  1129.626588           TARGET62338-99058  2019         3   \n",
       "8676   1987.50  1985.799547       WALMART US62338-92944  2018        10   \n",
       "8678   1837.75  1699.434295       WALMART US62338-92944  2018        11   \n",
       "8682   1686.40  1457.249969       WALMART US62338-92944  2018        12   \n",
       "8687   2118.25  1564.488075       WALMART US62338-92944  2019         1   \n",
       "8691   1730.75  1369.766141       WALMART US62338-92944  2019         2   \n",
       "8695   1724.80  1593.184298       WALMART US62338-92944  2019         3   \n",
       "8700   1325.50  1454.457709       WALMART US62338-92944  2019         4   \n",
       "8990   2942.00  2913.516138       WALMART US62338-99058  2018        10   \n",
       "8992   2497.25  2861.980094       WALMART US62338-99058  2018        11   \n",
       "8996   2384.80  2659.147461       WALMART US62338-99058  2018        12   \n",
       "9001   2962.25  2651.142856       WALMART US62338-99058  2019         1   \n",
       "9005   2663.25  2633.571525       WALMART US62338-99058  2019         2   \n",
       "9009   2652.40  2906.099439       WALMART US62338-99058  2019         3   \n",
       "9014   2274.00  2761.941726       WALMART US62338-99058  2019         4   \n",
       "9304   3699.50  4185.838930  ALL OTHERS - US51700-77050  2018        10   \n",
       "9306   3182.75  4137.558937  ALL OTHERS - US51700-77050  2018        11   \n",
       "9310   5027.40  4174.521883  ALL OTHERS - US51700-77050  2018        12   \n",
       "9315   3130.00  4157.257214  ALL OTHERS - US51700-77050  2019         1   \n",
       "9319   3861.25  4165.805847  ALL OTHERS - US51700-77050  2019         2   \n",
       "9323   4284.60  4202.768794  ALL OTHERS - US51700-77050  2019         3   \n",
       "9328   2269.00  4100.297094  ALL OTHERS - US51700-77050  2019         4   \n",
       "10880  1500.80   881.324553           KROGER51700-77050  2018        12   \n",
       "11816  2845.00  3087.112347       WALMART US51700-77050  2018        10   \n",
       "11818  2896.75  3128.892558       WALMART US51700-77050  2018        11   \n",
       "11822  2906.00  3169.340551       WALMART US51700-77050  2018        12   \n",
       "11827  3201.75  3300.766460       WALMART US51700-77050  2019         1   \n",
       "11831  2841.75  3281.084063       WALMART US51700-77050  2019         2   \n",
       "11835  3076.20  3208.388051       WALMART US51700-77050  2019         3   \n",
       "11840  2070.50  2993.599701       WALMART US51700-77050  2019         4   \n",
       "12130  1657.00  1987.576314  ALL OTHERS - US19200-79329  2018        10   \n",
       "12132  1318.00  1939.296321  ALL OTHERS - US19200-79329  2018        11   \n",
       "12136  2183.00  1976.259267  ALL OTHERS - US19200-79329  2018        12   \n",
       "12141  1561.75  1958.994598  ALL OTHERS - US19200-79329  2019         1   \n",
       "12145  2035.50  1967.543231  ALL OTHERS - US19200-79329  2019         2   \n",
       "12149  2387.40  2004.506177  ALL OTHERS - US19200-79329  2019         3   \n",
       "12760  1200.25   724.293886        DRUGSTORE19200-79329  2018        11   \n",
       "12764  1661.20   761.256832        DRUGSTORE19200-79329  2018        12   \n",
       "12769  1214.75   743.992163        DRUGSTORE19200-79329  2019         1   \n",
       "14956  1302.00  3828.991114       WALMART US19200-79329  2018        10   \n",
       "14958  2577.50  3780.711121       WALMART US19200-79329  2018        11   \n",
       "14962  5861.00  3817.674067       WALMART US19200-79329  2018        12   \n",
       "14967  9319.00  3800.409398       WALMART US19200-79329  2019         1   \n",
       "14975  3230.60  3845.920978       WALMART US19200-79329  2019         3   \n",
       "\n",
       "            MAD      MAPE  \n",
       "204    0.066023  0.061934  \n",
       "213    0.220193  0.282369  \n",
       "217    0.254263  0.340956  \n",
       "512    0.041955  0.043792  \n",
       "514    0.050772  0.053488  \n",
       "518    0.197367  0.245900  \n",
       "523    0.097133  0.107583  \n",
       "527    0.409493  0.693461  \n",
       "531    0.263016  0.356881  \n",
       "845    3.573604  0.781354  \n",
       "2396   0.601921  0.375750  \n",
       "2398   0.758915  0.431468  \n",
       "2402   0.464290  0.317075  \n",
       "3024   2.655754  0.726459  \n",
       "3026   7.739832  0.885581  \n",
       "8054   0.072515  0.067612  \n",
       "8067   0.051014  0.053756  \n",
       "8676   0.000856  0.000856  \n",
       "8678   0.081389  0.075264  \n",
       "8682   0.157248  0.135881  \n",
       "8687   0.353957  0.261424  \n",
       "8691   0.263537  0.208571  \n",
       "8695   0.082612  0.076308  \n",
       "8700   0.088664  0.097290  \n",
       "8990   0.009776  0.009682  \n",
       "8992   0.127440  0.146053  \n",
       "8996   0.103171  0.115040  \n",
       "9001   0.117348  0.105024  \n",
       "9005   0.011269  0.011144  \n",
       "9009   0.087299  0.095649  \n",
       "9014   0.176666  0.214574  \n",
       "9304   0.116187  0.131461  \n",
       "9306   0.230766  0.299995  \n",
       "9310   0.204306  0.169646  \n",
       "9315   0.247100  0.328197  \n",
       "9319   0.073109  0.078875  \n",
       "9323   0.019471  0.019099  \n",
       "9328   0.446625  0.807094  \n",
       "10880  0.702891  0.412763  \n",
       "11816  0.078427  0.085101  \n",
       "11818  0.074193  0.080139  \n",
       "11822  0.083090  0.090620  \n",
       "11827  0.029998  0.030926  \n",
       "11831  0.133899  0.154600  \n",
       "11835  0.041201  0.042971  \n",
       "11840  0.308358  0.445834  \n",
       "12130  0.166321  0.199503  \n",
       "12132  0.320372  0.471393  \n",
       "12136  0.104612  0.094705  \n",
       "12141  0.202780  0.254359  \n",
       "12145  0.034539  0.033386  \n",
       "12149  0.191017  0.160381  \n",
       "12760  0.657131  0.396547  \n",
       "12764  1.182181  0.541743  \n",
       "12769  0.632746  0.387535  \n",
       "14956  0.659963  1.940853  \n",
       "14958  0.318250  0.466813  \n",
       "14962  0.535228  0.348631  \n",
       "14967  1.452104  0.592187  \n",
       "14975  0.159993  0.190466  "
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data[final_data['Sales']>1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = final_data.sort_values(by='Sales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data['Sales_perc'] = round(100*final_data.Sales.cumsum(axis = 0) /final_data.Sales.sum(),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = test.copy()\n",
    "test2['y_pred'] = np.array(gbm.predict(X_test_scaled))\n",
    "test2['Customer_SKU'] = test2.merge(data_labels, left_index=True, right_index=True)['SKU_Customer']\n",
    "test2['y_pred'] = np.array(test2.groupby(['Customer_SKU', 'Year', 'Month_No', ]).y_pred.transform('sum'))\n",
    "\n",
    "final_data = test2[['Sales', 'y_pred', 'Customer_SKU', 'Year', 'Month_No']]\n",
    "final_data = final_data.drop_duplicates()\n",
    "\n",
    "\n",
    "final_data['MAD'] = np.where((final_data['y_pred'] == 0)&(final_data['Sales'] == 0), 0, \\\n",
    "                           np.where((final_data['y_pred'] == 0)&(final_data['Sales']!=0),1, np.abs(final_data['y_pred']-final_data['Sales'])/final_data['y_pred']))\n",
    " \n",
    "final_data['MAPE'] = np.where((final_data['y_pred'] == 0)&(final_data['Sales'] == 0), 0, \\\n",
    "                           np.where((final_data['y_pred'] != 0)&(final_data['Sales']==0),1, np.abs(final_data['y_pred']-final_data['Sales'])/final_data['Sales']))\n",
    "\n",
    "    \n",
    "print(final_data['MAD'].mean())   \n",
    "print(final_data['MAPE'].mean())     \n",
    "print(rmse_by_month(final_data['Sales'], final_data['y_pred']))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = test.copy()\n",
    "test2['y_pred'] = np.array(ridge_cv.predict(X_test_scaled))\n",
    "test2['SKU_Customer'] = test2.merge(data_labels, left_index=True, right_index=True)['SKU_Customer']\n",
    "\n",
    "final_data = test2[['Sales', 'y_pred', 'SKU_Customer', 'Year', 'Month_No']]\n",
    "final_data = final_data.drop_duplicates()\n",
    "\n",
    "\n",
    "final_data['MAD'] = np.where((final_data['y_pred'] == 0)&(final_data['Sales'] == 0), 0, \\\n",
    "                           np.where((final_data['y_pred'] == 0)&(final_data['Sales']!=0),1, np.abs(final_data['y_pred']-final_data['Sales'])/final_data['y_pred']))\n",
    " \n",
    "final_data['MAPE'] = np.where((final_data['y_pred'] == 0)&(final_data['Sales'] == 0), 0, \\\n",
    "                           np.where((final_data['y_pred'] != 0)&(final_data['Sales']==0),1, np.abs(final_data['y_pred']-final_data['Sales'])/final_data['Sales']))\n",
    "\n",
    "    \n",
    "print(final_data['MAD'].mean())   \n",
    "print(final_data['MAPE'].mean())     \n",
    "print(rmse_by_month(final_data['Sales'], final_data['y_pred']) )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
