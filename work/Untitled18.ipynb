{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:23: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  data_klasses = (pandas.Series, pandas.DataFrame, pandas.Panel)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "\n",
    "import statsmodels\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from pandas import Timestamp\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBRegressor \n",
    "from xgboost.sklearn import XGBClassifier # sklearnâ€™s Grid Search with parallel processing\n",
    "from xgboost import plot_importance\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "from pmdarima.arima import auto_arima\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('DF_File_sample.csv')\n",
    "data['SKU_Customer'] = data['DemandCustomer'] + '_' + data['SKU10']\n",
    "data_labels = data['SKU_Customer'] \n",
    "data.drop(['DemandCustomer', 'SKU10'], axis =1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['year_week'] = data['Year'].astype(str) + '-' + data['Week_No'].astype(str)\n",
    "data['date'] = data['year_week'].apply(lambda x: datetime.datetime.strptime(x + '-4',  \"%G-%V-%w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Sales'] = data.groupby(['SKU_Customer', 'Year', 'Month_No']).Sales.transform('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_null = data.groupby('date').Sales.sum().loc[lambda x: x == 0].sort_values().index[0]\n",
    "data = data[data.date < first_null]\n",
    "\n",
    "first_26_week = pd.Series(sorted(data['date'].unique())).iloc[-26]\n",
    "first_34_week = pd.Series(sorted(data['date'].unique())).iloc[-34]\n",
    "\n",
    "data.set_index('date', inplace = True)\n",
    "data = data.iloc[np.lexsort((data.SKU_Customer.values, data.index)), [5, 7]]\n",
    "\n",
    "train = data[data.index < first_34_week]\n",
    "test = data[data.index >= first_26_week]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "def timeseriesCVscore(params, series, loss_function=mean_squared_error, slen=24):\n",
    "    \"\"\"\n",
    "        Returns error on CV  \n",
    "        \n",
    "        params - vector of parameters for optimization\n",
    "        series - dataset with timeseries\n",
    "        slen - season length for Holt-Winters model\n",
    "    \"\"\"\n",
    "    # errors array\n",
    "    errors = []\n",
    "    \n",
    "    values = series.values\n",
    "    alpha, beta, gamma = params\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits = 5) \n",
    "    \n",
    "    # iterating over folds, train model on each, forecast and calculate error\n",
    "    for train, test in tscv.split(values):\n",
    "\n",
    "        model = HoltWinters(series=values[train], slen=slen, \n",
    "                            alpha=alpha, beta=beta, gamma=gamma, n_preds=len(test))\n",
    "        \n",
    "        model.triple_exponential_smoothing()\n",
    "        predictions = model.result[-len(test):]\n",
    "        actual = values[test]\n",
    "        error = loss_function(predictions, actual)\n",
    "        errors.append(error)\n",
    "        \n",
    "    return np.mean(np.array(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'minimize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-0ff5362066a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Minimizing the loss function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m opt = minimize(timeseriesCVscore, \n\u001b[0m\u001b[0;32m      6\u001b[0m                \u001b[0mx0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_squared_log_error\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'minimize' is not defined"
     ]
    }
   ],
   "source": [
    "# initializing model parameters alpha, beta and gamma\n",
    "x = [0, 0, 0] \n",
    "\n",
    "# Minimizing the loss function \n",
    "opt = minimize(timeseriesCVscore, \n",
    "               x0=x, \n",
    "               args=(data, mean_squared_log_error), \n",
    "               method=\"TNC\", bounds = ((0, 1), (0, 1), (0, 1)))\n",
    "\n",
    "alpha_final, beta_final, gamma_final = opt.x\n",
    "print(alpha_final, beta_final, gamma_final)\n",
    "\n",
    "# ...and train the model with them, forecasting for the next 50 hours\n",
    "model = HoltWinters(data, slen = 24, \n",
    "                    alpha = alpha_final, \n",
    "                    beta = beta_final, \n",
    "                    gamma = gamma_final, \n",
    "                    n_preds = 50, \n",
    "                    scaling_factor = 3)\n",
    "\n",
    "model.triple_exponential_smoothing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotHoltWinters(series, plot_intervals=False, plot_anomalies=False):\n",
    "    \"\"\"\n",
    "        series - dataset with timeseries\n",
    "        plot_intervals - show confidence intervals\n",
    "        plot_anomalies - show anomalies \n",
    "    \"\"\"\n",
    "    \n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.plot(model.result, label = \"Model\")\n",
    "    plt.plot(series.values, label = \"Actual\")\n",
    "    error = mean_absolute_percentage_error(series.values, model.result[:len(series)])\n",
    "    plt.title(\"Mean Absolute Percentage Error: {0:.2f}%\".format(error))\n",
    "    \n",
    "    if plot_anomalies:\n",
    "        anomalies = np.array([np.NaN]*len(series))\n",
    "        anomalies[series.values<model.LowerBond[:len(series)]] = \\\n",
    "            series.values[series.values<model.LowerBond[:len(series)]]\n",
    "        anomalies[series.values>model.UpperBond[:len(series)]] = \\\n",
    "            series.values[series.values>model.UpperBond[:len(series)]]\n",
    "        plt.plot(anomalies, \"o\", markersize=10, label = \"Anomalies\")\n",
    "    \n",
    "    if plot_intervals:\n",
    "        plt.plot(model.UpperBond, \"r--\", alpha=0.5, label = \"Up/Low confidence\")\n",
    "        plt.plot(model.LowerBond, \"r--\", alpha=0.5)\n",
    "        plt.fill_between(x=range(0,len(model.result)), y1=model.UpperBond, \n",
    "                         y2=model.LowerBond, alpha=0.2, color = \"grey\")    \n",
    "        \n",
    "    plt.vlines(len(series), ymin=min(model.LowerBond), ymax=max(model.UpperBond), linestyles='dashed')\n",
    "    plt.axvspan(len(series)-20, len(model.result), alpha=0.3, color='lightgrey')\n",
    "    plt.grid(True)\n",
    "    plt.axis('tight')\n",
    "    plt.legend(loc=\"best\", fontsize=13);\n",
    "    \n",
    "plotHoltWinters(ads.Ads)\n",
    "plotHoltWinters(ads.Ads, plot_intervals=True, plot_anomalies=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
